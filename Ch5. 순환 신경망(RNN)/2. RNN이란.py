### RNN이란 ###

# RNN, Recurrent Neural Network로 순환하는 신경망을 뜻한다.

### 순환하는 신경망
# 순환 : 어느 한 지점에서 시작한 것이 시간을 지나 다시 원래 장소로 돌아오는 것.
# 순환하기 위해서 '닫힌 경로(순환하는 경로)'가 필요하다!
# 데이터가 '닫힌 경로'(순환하는 경로)를 통해 같은 장소를 반복해 왕래하며 정보가 끊임없이 갱신된다.

# 비유
# 몸에 흐르는 혈액은 어제부터 계속해서 흐르던 혈액이다. 생명을 얻은 순간부터 계속 흐르기 시작했고 과거로부터 현재로 끊임없이 '갱신'된다.

# RNN의 특징은 '순환하는 경로'에 있으며 이 경로를 따라 데이터가 끊임없이 순환할 수 있다. 
# 데이터가 순환하기 때문에 과거의 정보를 기억하는 동시, 최신 데이터로 갱신될 수 있다!

# RNN 계층은 입력으로 x.t를 입력 받고 h.t를 출력하는데 여기서 t는 시각을 뜻한다.(시계열 데이터를 나타내기 위함, 문장의 순서 w1다음w2다음w3)
# 각 시각에 입력되는 x.t는 벡터라고 가정한다. 문장을 다루는 경우를 예로 들면 각 단어의 분산 표현이 x.t가 된다.


### 순환 구조 펼치기
# 순환구조를 오른쪽으로 연속해서 나열하면 마치 긴 신경망 처럼 보이게 된다.
# 피드포워드 신경망과 유사하지만 다른 점은 RNN 각 계층 모두가 실제로는 '같은 계층'이라는 것이다.

# cf) 
# 시계열 데이터는 시간 방향으로 데이터가 나열된다. 따라서 시계열 데이터의 인덱스를 가리킬 때는 '시각'이라는 용어를 사용한다.
# ex) 시각 t의 단어, 시각 t의 RNN 계층 == t번째 단어, t번째 RNN 계층

# 각 시각의 RNN 계층은 그 계층으로의 입력과 1개 전의 RNN 계층으로부터의 출력을 받게 된다.
# 두 정보를 바타응로 현 시각의 출력을 계산하게 된다. # 수행하는 계산식은 다음과 같다.
# h.t = tanh(h.t-1 x W.h + x.t x W.x + b)
# 입력 x를 출력 h로 변환하기 위한 가중치 W.t 
# RNN 출력을 다음 시각의 출력을 변환하기 위한 W.h
# h.t-1과 x.t는 모두 벡터이다
# h.t는 다른 계층을 향해 위로 출력되는 동시에 다음 시각의 RNN 계층을 위해 오른쪽으로도 출력된다.(동일한 값)
# h.t는 h.t-1에 기초해 계산되게 되는데 다른 관점으로 해석하면 RNN은 h라는 '상태'를 가지며
# h.t = tanh(h.t-1 x W.h + x.t x W.x + b) 식을 통해 상태가 갱신된다.
# 즉 RNN 계층을 '상태를 가지는 계층' or '메모리(기억력)을 가지는 계층' 이라고 한다.




### BPTT(Backpropagation Through Time)
# 시간 방향으로 펼쳐진 신경망의 오차 역전파법, RNN 계층과 Input 계층 모두의 가중치가 갱신된다.
# 긴 시계열 데이터를 학습할 때 데이터가 커질 수록 BPTT가 소비하는 컴퓨팅 자원도 증가하게 된다.(문제점)
# 시간 크기가 커지면 역전파 시의 기울기가 불안정해진다.
# RNN에서 역전파를 활용해 기울기를 구하려면 RNN 계층의 중간 데이터를 메모리에 유지해야하므로 시계열이 길어짐에 따라 메모리 사용도 증가하게 된다.




### Truncated BPTT
# BPTT의 문제점(큰 시계데이터에서의 역전파)를 해결하기 위해 '순전파'에서는 모든 RNN 계층을 연결하지만 '역전파'에서는 적당한 길이로 잘라낸다.
# 역전파는 위쪽(out방향)에서 손실은 계산한 것을 아래 방향으로 역전파 시키는 것이며 이때 전의 RNN 계층들에도 역전파를 수행한다.
# 순전파의 연결은 끊기면 안 되며(데이터의 순서를 고려해야한다!) 오직 역전파일 때 자르는 것이다!


### Truncated BPTT의 미니배치 학습
# 길이가 1000인 시계열 데이터를 학습한다고 했을 때, batch size를 2로 설정하고 10개 단위로 잘라 Truncated BPTT 학습을 진행하는 경우
# x0 ~ x499 까지를 10개의 세트로 (x0~x9),(x10~x19),...(x490~x499)를 첫 번째 미니 배치로써 학습을 진행한다.
# 이후 x500을 시작위치로 지정하여 위와 같은 방법으로 (x500~x509),(x510~x519),...로 학습을 진행한다.